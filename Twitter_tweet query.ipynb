{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOreruB-C37L"
      },
      "outputs": [],
      "source": [
        "#ASSIGNMENT\n",
        "#Part 1: Ingesting the data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/dataset/correct_twitter_201904.tsv'\n",
        "chunk_size = 10**6\n",
        "chunks = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size)\n",
        "\n",
        "\n",
        "# Combining chunks into a single DataFrame\n",
        "tweets_df = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "# converting created_at to datetime format\n",
        "# converting created_at to datetime format\n",
        "tweets_df['created_at'] = pd.to_datetime(tweets_df['created_at'], errors='coerce', utc=True)\n",
        "\n",
        "#Cleaning the data for better results\n",
        "# Handling Missing Values- removing blank rows and filling blank rows as needed\n",
        "tweets_df.dropna(subset=['created_at', 'text'], inplace=True)\n",
        "tweets_df['like_count'].fillna(tweets_df['like_count'].mean(), inplace=True)\n",
        "\n",
        "\n",
        "#Handling Duplicates\n",
        "tweets_df.drop_duplicates(subset=['text'], inplace=True)\n",
        "\n",
        "#Handling Inconsistent Data\n",
        "tweets_df['text'] = tweets_df['text'].str.lower().str.strip()\n",
        "tweets_df['text'] = tweets_df['text'].str.replace('teh', 'the')\n",
        "\n",
        "#Outlier Handling (example for 'like_count')\n",
        "Q1 = tweets_df['like_count'].quantile(0.25)\n",
        "Q3 = tweets_df['like_count'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "tweets_df = tweets_df[(tweets_df['like_count'] >= Q1 - 1.5 * IQR) & (tweets_df['like_count'] <= Q3 + 1.5 * IQR)]\n",
        "tweets_df.head()\n",
        "\n",
        "#print(tweets_df.head())\n",
        "\n",
        "\n",
        "# PART 2: Revised Query Functionality with User Input\n",
        "def query_tweets(df):\n",
        "    search_term = input(\"Enter the term you want to search for (or 'na' for no specific term): \").strip()\n",
        "\n",
        "    # If user inputs 'na', return a message and exit the function\n",
        "    if search_term.lower() == 'na':\n",
        "        print(\"No specific term was searched.\")\n",
        "        return\n",
        "\n",
        "    # Filter tweets that contain the search term\n",
        "    filtered_tweets = df[df['text'].str.contains(search_term, case=False, na=False)]\n",
        "\n",
        "    # Checking if filtered tweets are empty\n",
        "    if filtered_tweets.empty:\n",
        "        print(f\"No tweets found for the term '{search_term}'.\")\n",
        "        return\n",
        "\n",
        "    # Ensure 'created_at' in filtered_tweets is datetime\n",
        "    #filtered_tweets['created_at'] = pd.to_datetime(filtered_tweets['created_at'], errors='coerce')\n",
        "\n",
        "#1.How many tweets were posted containing the term on each day?\n",
        "    tweets_per_day = filtered_tweets['created_at'].dt.date.value_counts().sort_index()\n",
        "#2.How many unique users posted a tweet containing the term?\n",
        "    unique_users = filtered_tweets['author_id'].nunique()\n",
        "#3.How many likes did tweets containing the term get, on average?\n",
        "    average_likes = filtered_tweets['like_count'].mean()\n",
        "#4.Where (in terms of place IDs) did the tweets come from?\n",
        "    tweets_by_place = filtered_tweets['place_id'].value_counts().head(10)  # Show top 10 places\n",
        "#5.What times of day were the tweets posted at?\n",
        "    tweets_by_time = filtered_tweets['created_at'].dt.hour.value_counts().sort_index()\n",
        "#6.Which user posted the most tweets containing the term?\n",
        "    most_active_user = filtered_tweets['author_handle'].value_counts().idxmax()\n",
        "\n",
        "\n",
        "    print(f\"\\nResults for search term: '{search_term}'\\n\")\n",
        "\n",
        "    print(\"Tweets per day:\")\n",
        "    for date, count in tweets_per_day.items():\n",
        "        print(f\"{date}: {count}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(f\"Unique users: {unique_users}\")\n",
        "    print(f\"Average likes per tweet: {average_likes:.2f}\\n\")\n",
        "\n",
        "    print(\"Tweets by place (place IDs - Top 10):\")\n",
        "    for place_id, count in tweets_by_place.items():\n",
        "        print(f\"{place_id}: {count}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Tweets by hour:\")\n",
        "    for hour, count in tweets_by_time.items():\n",
        "        print(f\"{hour:02d}:00 - {hour:02d}:59: {count}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(f\"Most active user: {most_active_user}\\n\")\n",
        "\n",
        "\n",
        "query_tweets(tweets_df)\n",
        "\n"
      ]
    }
  ]
}